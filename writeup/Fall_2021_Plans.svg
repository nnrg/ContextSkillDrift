<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!-- Created with Inkscape (http://www.inkscape.org/) -->

<svg
   width="30in"
   height="30in"
   viewBox="0 0 762.00001 762.00002"
   version="1.1"
   id="svg5"
   inkscape:version="1.1 (1:1.1+202105261517+ce6663b3b7)"
   sodipodi:docname="Fall_2021_Plans.svg"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:svg="http://www.w3.org/2000/svg">
  <sodipodi:namedview
     id="namedview7"
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1.0"
     inkscape:pageshadow="2"
     inkscape:pageopacity="0.0"
     inkscape:pagecheckerboard="0"
     inkscape:document-units="mm"
     showgrid="false"
     inkscape:zoom="0.75187991"
     inkscape:cx="347.7949"
     inkscape:cy="994.17472"
     inkscape:window-width="1848"
     inkscape:window-height="1016"
     inkscape:window-x="72"
     inkscape:window-y="27"
     inkscape:window-maximized="1"
     inkscape:current-layer="layer1"
     units="in"
     width="30in" />
  <defs
     id="defs2" />
  <g
     inkscape:label="Layer 1"
     inkscape:groupmode="layer"
     id="layer1">
    <text
       xml:space="preserve"
       style="font-style:normal;font-weight:normal;font-size:5.64444px;line-height:1.25;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:0.264583"
       x="91.312302"
       y="50.708549"
       id="text2032"><tspan
         sodipodi:role="line"
         id="tspan2030"
         style="font-size:5.64444px;stroke-width:0.264583"
         x="91.312302"
         y="50.708549">Information</tspan><tspan
         sodipodi:role="line"
         style="font-size:5.64444px;stroke-width:0.264583"
         x="91.312302"
         y="57.764103"
         id="tspan4784">About</tspan><tspan
         sodipodi:role="line"
         style="font-size:5.64444px;stroke-width:0.264583"
         x="91.312302"
         y="64.819649"
         id="tspan4782">Recent Data</tspan><tspan
         sodipodi:role="line"
         style="font-size:5.64444px;stroke-width:0.264583"
         x="91.312302"
         y="71.875198"
         id="tspan3086">(Batch N)</tspan></text>
    <text
       xml:space="preserve"
       style="font-style:normal;font-weight:normal;font-size:5.64444px;line-height:1.25;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:0.264583"
       x="72.865036"
       y="122.8751"
       id="text2032-3"><tspan
         sodipodi:role="line"
         id="tspan2030-6"
         style="font-size:5.64444px;stroke-width:0.264583"
         x="72.865036"
         y="122.8751">Information</tspan><tspan
         sodipodi:role="line"
         style="font-size:5.64444px;stroke-width:0.264583"
         x="72.865036"
         y="129.93065"
         id="tspan3490">About Recent</tspan><tspan
         sodipodi:role="line"
         style="font-size:5.64444px;stroke-width:0.264583"
         x="72.865036"
         y="136.98621"
         id="tspan3492">Batches</tspan><tspan
         sodipodi:role="line"
         style="font-size:5.64444px;stroke-width:0.264583"
         x="72.865036"
         y="144.04175"
         id="tspan3494">(Batch N-1, N-2, ..., N-p)</tspan><tspan
         sodipodi:role="line"
         style="font-size:5.64444px;stroke-width:0.264583"
         x="72.865036"
         y="151.09731"
         id="tspan3496" /><tspan
         sodipodi:role="line"
         style="font-size:5.64444px;stroke-width:0.264583"
         x="72.865036"
         y="158.15285"
         id="tspan3498" /></text>
    <text
       xml:space="preserve"
       style="font-style:normal;font-weight:normal;font-size:4.23333px;line-height:1.25;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:0.264583"
       x="9.9300604"
       y="188.88466"
       id="text2032-3-7"><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="188.88466"
         id="tspan19167">The model is that we are trying to predict a distribution. We assume that the data</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="194.17632"
         id="tspan19171">is drawn from distributions per-batch: there are distributions D_t, D_{t+1}, and</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="199.46799"
         id="tspan19173">t ranges from t \in { 1, 2, 3, ..., 10 }. Each batch represents a session of recorded data,</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="204.75964"
         id="tspan19175">and there was as many as several months between recording sessions.</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="210.0513"
         id="tspan19177" /><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="215.34297"
         id="tspan19181">Subsequently, we assume that there is a &quot;hidden process&quot; (cite) that generates the data.</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="220.63463"
         id="tspan19185">The hidden process is represented by a latent &quot;hidden state&quot; variable by the variable h.</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="225.9263"
         id="tspan19187">The vector h_{t} represents the latent state vector representing the hidden process.</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="231.21796"
         id="tspan19189">There is then a stochastic process \Phi which defines the dynamics of the hidden</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="236.50961"
         id="tspan19191">state over time. We assume a function:</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="241.80128"
         id="tspan21539">    h__{t+1} ~ \Phi( h_{t} )</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="247.09294"
         id="tspan21543" /><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="252.38461"
         id="tspan21545">The latent state paramaterises a data distribution P(y, x | h_t ).</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="257.67627"
         id="tspan22555" /><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="262.96793"
         id="tspan22557">We estimate both the latent dynamics and the sample density function using</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="268.25958"
         id="tspan32161">neural networks. </tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="273.55127"
         id="tspan32163">First, we assume that the network has some estimate of the &quot;current&quot; hidden state,</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="278.84293"
         id="tspan32677">and this estimate we will represent by the variable \hat{h}.</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="284.13458"
         id="tspan32165">Under this theory {cite}, we use residual recurrent neural networks. These functions</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="289.42624"
         id="tspan32167">&quot;build up&quot; a state representation over several time-steps. We also compare with</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="294.7179"
         id="tspan32169">LSTMs, which are standard practice.</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="300.00955"
         id="tspan19193">Then, we will try to estimate the function \Phi. We first note that \Phi gets its loss</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="305.30124"
         id="tspan33363">signal according to the density function.</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="310.5929"
         id="tspan33365">Suppose we have \hat{h}_{t-1}, per the assumption above. Then,</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="315.88455"
         id="tspan34243">we will use the estimator of \Phi, which we call F_1, in order to generate</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="321.17621"
         id="tspan34247">the value \hat{h}_t. F_1 will be &quot;graded&quot; on the ability of \hat{h}_t to inform</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="326.46786"
         id="tspan34249">predictions about P(y, x | h_t ). This train of thought leads to this density estimator.</tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="331.75955"
         id="tspan34529">First, the task of the classifier is to estimate the function P(y | x, h_t). </tspan><tspan
         sodipodi:role="line"
         style="font-size:4.23333px;stroke-width:0.264583"
         x="9.9300604"
         y="337.05121"
         id="tspan33361" /></text>
    <text
       xml:space="preserve"
       style="font-style:normal;font-weight:normal;font-size:5.64444px;line-height:1.25;font-family:sans-serif;letter-spacing:0px;word-spacing:0px;fill:#000000;fill-opacity:1;stroke:none;stroke-width:0.264583"
       x="215.45267"
       y="93.717484"
       id="text2617"><tspan
         sodipodi:role="line"
         id="tspan2615"
         style="font-size:5.64444px;stroke-width:0.264583"
         x="215.45267"
         y="93.717484">Attention</tspan><tspan
         sodipodi:role="line"
         style="font-size:5.64444px;stroke-width:0.264583"
         x="215.45267"
         y="100.77303"
         id="tspan2641">Network</tspan></text>
  </g>
</svg>
